<!DOCTYPE html><html lang="en" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1"><title>Deep Ensembles: A Loss Landscape Perspective (2020) Paper Reading | Hualong Deng's Blog</title><meta name="description" content="Paper address：https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;1912.02757.pdf IntroductionThis paper is written by Stanislav Fort (Google Research), Huiyi Hu (DeepMind), Balaji Lakshminarayanan (DeepMind). The target of this pa"><meta name="author" content="Hualong Deng,hualongdeng1996@gmail.com"><meta name="copyright" content="Hualong Deng"><meta name="format-detection" content="telephone=no"><link rel="shortcut icon" href="/blog.github.io/img/favicon.png"><link rel="canonical" href="https://hualongdeng.github.io/blog.github.io/2020/08/22/Deep-Ensembles-A-Loss-Landscape-Perspective-en/"><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//fonts.googleapis.com" crossorigin="crossorigin"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><meta property="og:type" content="article"><meta property="og:title" content="Deep Ensembles: A Loss Landscape Perspective (2020) Paper Reading"><meta property="og:url" content="https://hualongdeng.github.io/blog.github.io/2020/08/22/Deep-Ensembles-A-Loss-Landscape-Perspective-en/"><meta property="og:site_name" content="Hualong Deng's Blog"><meta property="og:description" content="Paper address：https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;1912.02757.pdf IntroductionThis paper is written by Stanislav Fort (Google Research), Huiyi Hu (DeepMind), Balaji Lakshminarayanan (DeepMind). The target of this pa"><meta property="og:image" content="https://drive.google.com/uc?export=view&amp;id=16QZxIsrE1YY_3AnGzaV9pN9DTUUOko4r"><meta property="article:published_time" content="2020-08-22T04:46:41.000Z"><meta property="article:modified_time" content="2020-08-25T12:43:58.509Z"><meta name="twitter:card" content="summary"><script>var activateDarkMode = function () {
  document.documentElement.setAttribute('data-theme', 'dark')
  if (document.querySelector('meta[name="theme-color"]') !== null) {
    document.querySelector('meta[name="theme-color"]').setAttribute('content', '#000')
  }
}
var activateLightMode = function () {
  document.documentElement.setAttribute('data-theme', 'light')
  if (document.querySelector('meta[name="theme-color"]') !== null) {
    document.querySelector('meta[name="theme-color"]').setAttribute('content', '#fff')
  }
}

var getCookies = function (name) {
  const value = `; ${document.cookie}`
  const parts = value.split(`; ${name}=`)
  if (parts.length === 2) return parts.pop().split(';').shift()
}

var autoChangeMode = 'false'
var t = getCookies('theme')
if (autoChangeMode === '1') {
  var isDarkMode = window.matchMedia('(prefers-color-scheme: dark)').matches
  var isLightMode = window.matchMedia('(prefers-color-scheme: light)').matches
  var isNotSpecified = window.matchMedia('(prefers-color-scheme: no-preference)').matches
  var hasNoSupport = !isDarkMode && !isLightMode && !isNotSpecified

  if (t === undefined) {
    if (isLightMode) activateLightMode()
    else if (isDarkMode) activateDarkMode()
    else if (isNotSpecified || hasNoSupport) {
      console.log('You specified no preference for a color scheme or your browser does not support it. I Schedule dark mode during night time.')
      var now = new Date()
      var hour = now.getHours()
      var isNight = hour <= 6 || hour >= 18
      isNight ? activateDarkMode() : activateLightMode()
    }
    window.matchMedia('(prefers-color-scheme: dark)').addListener(function (e) {
      if (Cookies.get('theme') === undefined) {
        e.matches ? activateDarkMode() : activateLightMode()
      }
    })
  } else if (t === 'light') activateLightMode()
  else activateDarkMode()
} else if (autoChangeMode === '2') {
  now = new Date()
  hour = now.getHours()
  isNight = hour <= 6 || hour >= 18
  if (t === undefined) isNight ? activateDarkMode() : activateLightMode()
  else if (t === 'light') activateLightMode()
  else activateDarkMode()
} else {
  if (t === 'dark') activateDarkMode()
  else if (t === 'light') activateLightMode()
}</script><link rel="stylesheet" href="/blog.github.io/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Titillium+Web&amp;display=swap"><script>var GLOBAL_CONFIG = { 
  root: '/blog.github.io/',
  hexoversion: '5.0.2',
  algolia: undefined,
  localSearch: undefined,
  translate: undefined,
  noticeOutdate: undefined,
  copy: {
    success: 'Copy successfully',
    error: 'Copy error',
    noSupport: 'The browser does not support'
  },
  bookmark: {
    message_prev: 'Press',
    message_next: 'to bookmark this page'
  },
  runtime_unit: 'days',
  runtime: false,
  copyright: undefined,
  ClickShowText: undefined,
  medium_zoom: false,
  fancybox: true,
  Snackbar: undefined,
  justifiedGallery: {
    js: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/js/jquery.justifiedGallery.min.js',
    css: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/css/justifiedGallery.min.css'
  },
  baiduPush: false,
  highlightCopy: true,
  highlightLang: true,
  isPhotoFigcaption: false,
  islazyload: true,
  isanchor: false    
}</script><script id="config_change">var GLOBAL_CONFIG_SITE = { 
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isSidebar: true,
  postUpdate: '2020-08-25 22:43:58'
}</script><noscript><style>
#nav {
  opacity: 1
}
.justified-gallery img {
  opacity: 1
}
</style></noscript><meta name="generator" content="Hexo 5.0.2"></head><body><div id="mobile-sidebar"><div id="menu_mask"></div><div id="mobile-sidebar-menus"><div class="mobile_author_icon"><img class="avatar-img" data-lazy-src="/blog.github.io/img/avatar.png" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="mobile_post_data"><div class="mobile_data_item is-center"><div class="mobile_data_link"><a href="/blog.github.io/archives/"><div class="headline">Articles</div><div class="length_num">3</div></a></div></div></div><hr/></div></div><div id="body-wrap"><div id="sidebar"><i class="fas fa-arrow-right on" id="toggle-sidebar"></i><div class="sidebar-toc"><div class="sidebar-toc__title">Catalog</div><div class="sidebar-toc__progress"><span class="progress-notice">You've read</span><span class="progress-num">0</span><span class="progress-percentage">%</span><div class="sidebar-toc__progress-bar">     </div></div><div class="sidebar-toc__content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#Introduction"><span class="toc-number">1.</span> <span class="toc-text">Introduction</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Background"><span class="toc-number">2.</span> <span class="toc-text">Background</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Theory-part"><span class="toc-number">3.</span> <span class="toc-text">Theory part</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Function-Space-Similarity"><span class="toc-number">4.</span> <span class="toc-text">Function Space Similarity</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#1-Similarity-of-Functions-Within-and-Across-Randomly-Initialized-Trajectories"><span class="toc-number">4.1.</span> <span class="toc-text">1. Similarity of Functions Within and Across Randomly Initialized Trajectories</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-Similarity-of-Functions-Within-Subspace-from-Each-Trajectory-and-Across-Trajectories"><span class="toc-number">4.2.</span> <span class="toc-text">2. Similarity of Functions Within Subspace from Each Trajectory and Across Trajectories</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3-Diversity-versus-Accuracy-plots"><span class="toc-number">4.3.</span> <span class="toc-text">3. Diversity versus Accuracy plots</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Relative-Effects-of-Ensembling-versus-Subspace-Methods"><span class="toc-number">5.</span> <span class="toc-text">Relative Effects of Ensembling versus Subspace Methods</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#1-Basic-Dtaset"><span class="toc-number">5.1.</span> <span class="toc-text">1. Basic Dtaset</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-Dataset-Shift"><span class="toc-number">5.2.</span> <span class="toc-text">2. Dataset Shift</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Summary"><span class="toc-number">6.</span> <span class="toc-text">Summary</span></a></li></ol></div></div></div><header class="post-bg" id="page-header" style="background-image: url(https://drive.google.com/uc?export=view&amp;id=16QZxIsrE1YY_3AnGzaV9pN9DTUUOko4r)"><nav id="nav"><span class="pull-left" id="blog_name"><a class="blog_title" id="site-name" href="/blog.github.io/">Hualong Deng's Blog</a></span><span class="pull-right menus"><span class="toggle-menu close"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></span></span></nav><div id="post-info"><div id="post-title"><div class="posttitle">Deep Ensembles: A Loss Landscape Perspective (2020) Paper Reading</div></div><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">Created</span><time class="post-meta-date-created" datetime="2020-08-22T04:46:41.000Z" title="Created 2020-08-22 14:46:41">2020-08-22</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">Updated</span><time class="post-meta-date-updated" datetime="2020-08-25T12:43:58.509Z" title="Updated 2020-08-25 22:43:58">2020-08-25</time></span></div><div class="meta-secondline"> <span class="post-meta-separator">|</span><span class="post-meta-pv-cv"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">Post View:</span><span id="busuanzi_value_page_pv"></span></span></div></div></div></header><main class="layout_post" id="content-inner"><article id="post"><div class="post-content" id="article-container"><p>Paper address：<a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1912.02757.pdf">https://arxiv.org/pdf/1912.02757.pdf</a></p>
<h1 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h1><p>This paper is written by Stanislav Fort (Google Research), Huiyi Hu (DeepMind), Balaji Lakshminarayanan (DeepMind). The target of this paper is to discuss why Deep Ensamble could have a great performance in practice. They propose a hypothesis that different random initialisation in Deep Ensamble could explore different modes, but approximate Bayesian neural network could only explore  one mode in solution space. In this paper, they use many experiments to test the hypothesis, and prove it finally.</p>
<h1 id="Background"><a href="#Background" class="headerlink" title="Background"></a>Background</h1><p>Deep ensemble: This ensemble is very similar with the ensemble in Random Forest, but the ensemble unit is neural network, not decision tree. And the output of Deep ensemble is by voting, just like Random Forest. This concept is from “Simple and Scalable Predictive Uncertainty Estimation using Deep Ensembles (2017) “ written by Balaji Lakshminarayanan and his colleagues. I introduce this paper in another article.<br>Compared to Bayesian neural network, it could keep uncertainty and also be efficient in computing, because it need no compute the posterior distribution.</p>
<p>Bayesian neural network: In normal neural network, the weight in network is just a value, and we change it in training process. But in Bayesian neural network, we use a distribution to represent the weight. The thing we train is the parameter of the distribution, like mean and variance.</p>
<h1 id="Theory-part"><a href="#Theory-part" class="headerlink" title="Theory part"></a>Theory part</h1><p>Due to the huge computation for exact posterior distribution in Bayesian neural network, there are many approximate method to make it efficient, such as Laplace approximation, Markov chain Monte Carlo methods, variational Bayesian methods and Monte-Carlo dropout. And we also could use maximum-a-posteriori (MAP) to get the mode of distribution and use it to represent whole distribution. However, it is just a point estimate and can not represent whole distribution well. Deep ensemble, we talked about it before, could keep the uncertainty and has relatively efficient computation. Following part, we will explore why it could perform well compared to Bayesian neural network and test the hypothesis. This image is from the paper and explains the hypothesis:</p>
<p><img src= "/blog.github.io/img/loading.gif" data-lazy-src="/blog.github.io/2020/08/22/Deep-Ensembles-A-Loss-Landscape-Perspective-en/Deep_Ensembles_A_Loss_Landscape_Perspective-1.jpg"></p>
<h1 id="Function-Space-Similarity"><a href="#Function-Space-Similarity" class="headerlink" title="Function Space Similarity"></a>Function Space Similarity</h1><p>This part is about some experiments to test the hypothesis before. There are three datasets used, CIFAR-10，CIFAR-100 and ImageNet. I will not talk about the details of parameter in experiments, and they are in the original paper. I will focus on the experiment results.</p>
<p>Similarity experiments has three parts, and the target is to judge the  similarity of two functions in function space. If two functions are similar, it means that they explore the same place in function space, which shows that they explore the same mode in the distribution.</p>
<h2 id="1-Similarity-of-Functions-Within-and-Across-Randomly-Initialized-Trajectories"><a href="#1-Similarity-of-Functions-Within-and-Across-Randomly-Initialized-Trajectories" class="headerlink" title="1. Similarity of Functions Within and Across Randomly Initialized Trajectories"></a>1. Similarity of Functions Within and Across Randomly Initialized Trajectories</h2><p>The first similarity experiment is between functions within a randomly initialised trajectory and functions across different  randomly initialised trajectories. This following plot shows the result of functions within a randomly initialised trajectory:</p>
<p><img src= "/blog.github.io/img/loading.gif" data-lazy-src="/blog.github.io/2020/08/22/Deep-Ensembles-A-Loss-Landscape-Perspective-en/Deep_Ensembles_A_Loss_Landscape_Perspective-2.jpg"></p>
<p>The (a) part is the result of cosine similarity. Red means high similarity and blue means low. The (b) part means the fraction of two functions give the different labels among all instances. Red means two functions disagree each other more, which shows they are not similar. Blue means often have the same output, which shows they are similar. The (c) part is the prediction result in t-SNE plot from three different trajectories. Different colours means different trajectories.</p>
<p>This following plot shows the result of functions across different randomly initialised trajectories:</p>
<p><img src= "/blog.github.io/img/loading.gif" data-lazy-src="/blog.github.io/2020/08/22/Deep-Ensembles-A-Loss-Landscape-Perspective-en/Deep_Ensembles_A_Loss_Landscape_Perspective-3.jpg"></p>
<p>(a) part and (b) part means two different datasets. The left plot in each datasets is the result of cosine similarity. The right plot is disagree situation.</p>
<p>Comparing (a) (b) part in first plot with the second plot, we could get that functions within a single trajectory exhibit higher similarity and functions across different trajectories exhibit much lower similarity. From (c) is the first plot, it shows that functions explored by different trajectories are far away, while functions explored within a single trajectory tend to be much more similar.</p>
<h2 id="2-Similarity-of-Functions-Within-Subspace-from-Each-Trajectory-and-Across-Trajectories"><a href="#2-Similarity-of-Functions-Within-Subspace-from-Each-Trajectory-and-Across-Trajectories" class="headerlink" title="2. Similarity of Functions Within Subspace from Each Trajectory and Across Trajectories"></a>2. Similarity of Functions Within Subspace from Each Trajectory and Across Trajectories</h2><p>Compared to the first experiment, the second one is to compare the subspace sampling results for optimal function in different trajectories. In this experiment, there are four subspace sampling methods: Random subspace sampling，Dropout subspace，Diagonal Gaussian subspace，Low-rank Gaussian subspace (About the details of these four methods, please go to read the original paper). The following plot is the first result:</p>
<p><img src= "/blog.github.io/img/loading.gif" data-lazy-src="/blog.github.io/2020/08/22/Deep-Ensembles-A-Loss-Landscape-Perspective-en/Deep_Ensembles_A_Loss_Landscape_Perspective-4.jpg"></p>
<p>It shows functions sampled from a subspace corresponding to a particular initialisation, are much more similar to each other.</p>
<p>The following plot is another experiment result：</p>
<p><img src= "/blog.github.io/img/loading.gif" data-lazy-src="/blog.github.io/2020/08/22/Deep-Ensembles-A-Loss-Landscape-Perspective-en/Deep_Ensembles_A_Loss_Landscape_Perspective-5.jpg"></p>
<p>The left subplot shows that different randomly initialised trajectories eventually achieve similar accuracy. The middle and the right subplots are the result show function space similarity (defined as the fraction of points on which they agree on the class prediction) of the parameters along the path to optima 1 and 2.</p>
<h2 id="3-Diversity-versus-Accuracy-plots"><a href="#3-Diversity-versus-Accuracy-plots" class="headerlink" title="3. Diversity versus Accuracy plots"></a>3. Diversity versus Accuracy plots</h2><p>The third experiments focuses on two parts, diversity and accuracy, between subspace sampling methods versus deep ensembles. This experiment uses diversity vs accuracy plot to explore if the method keeps accuracy and de-correlated both. The following two plots are the result:</p>
<p><img src= "/blog.github.io/img/loading.gif" data-lazy-src="/blog.github.io/2020/08/22/Deep-Ensembles-A-Loss-Landscape-Perspective-en/Deep_Ensembles_A_Loss_Landscape_Perspective-6.jpg"></p>
<p><img src= "/blog.github.io/img/loading.gif" data-lazy-src="/blog.github.io/2020/08/22/Deep-Ensembles-A-Loss-Landscape-Perspective-en/Deep_Ensembles_A_Loss_Landscape_Perspective-7.jpg"></p>
<p>They show that random initialisations are much more effective at sampling diverse and accurate solutions, than subspace based methods constructed out of a single trajectory.</p>
<h1 id="Relative-Effects-of-Ensembling-versus-Subspace-Methods"><a href="#Relative-Effects-of-Ensembling-versus-Subspace-Methods" class="headerlink" title="Relative Effects of Ensembling versus Subspace Methods"></a>Relative Effects of Ensembling versus Subspace Methods</h1><h2 id="1-Basic-Dtaset"><a href="#1-Basic-Dtaset" class="headerlink" title="1. Basic Dtaset"></a>1. Basic Dtaset</h2><p>This part is to investigate that if subspace-based methods and ensembling should provide complementary benefits in terms of uncertainty and accuracy on normal dataset. There are four variants being compared: baseline，subspace sampling，ensemble，subspace sampling + ensemble. The following plot is another experiment result:</p>
<p><img src= "/blog.github.io/img/loading.gif" data-lazy-src="/blog.github.io/2020/08/22/Deep-Ensembles-A-Loss-Landscape-Perspective-en/Deep_Ensembles_A_Loss_Landscape_Perspective-8.jpg"></p>
<p>The results shows that (i) subspace sampling and ensembling provide complementary benefits, and (ii) the relative benefits of ensembling are higher as it averages predictions over more diverse solutions.</p>
<h2 id="2-Dataset-Shift"><a href="#2-Dataset-Shift" class="headerlink" title="2. Dataset Shift"></a>2. Dataset Shift</h2><p>This part is the same as the previous one, but on dataset shift situation. The following two plots are the result on two datasets:</p>
<p><img src= "/blog.github.io/img/loading.gif" data-lazy-src="/blog.github.io/2020/08/22/Deep-Ensembles-A-Loss-Landscape-Perspective-en/Deep_Ensembles_A_Loss_Landscape_Perspective-9.jpg"></p>
<p><img src= "/blog.github.io/img/loading.gif" data-lazy-src="/blog.github.io/2020/08/22/Deep-Ensembles-A-Loss-Landscape-Perspective-en/Deep_Ensembles_A_Loss_Landscape_Perspective-10.jpg"></p>
<p>Both of them show that deep ensembles outperform other methods under dataset shift.</p>
<h1 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h1><p>The whole paper has proven that trajectories of randomly initialised neural networks explore different modes in function space, which explains why deep ensembles trained with just random initialisations work well in practice. Compared to huge computation of Bayesian neural network, Deep ensemble could keep uncertianty well as Bayesian neural network, and just need for cheap computation.</p>
</div><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">Author: </span><span class="post-copyright-info"><a href="mailto:hualongdeng1996@gmail.com">Hualong Deng</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">Link: </span><span class="post-copyright-info"><a href="https://hualongdeng.github.io/blog.github.io/2020/08/22/Deep-Ensembles-A-Loss-Landscape-Perspective-en/">https://hualongdeng.github.io/blog.github.io/2020/08/22/Deep-Ensembles-A-Loss-Landscape-Perspective-en/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">Copyright Notice: </span><span class="post-copyright-info">All articles in this blog are licensed under <a target="_blank" rel="noopener" href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0</a> unless stating additionally.</span></div></div><div class="tag_share"><div class="post-meta__tag-list"></div><div class="post_share"><div class="social-share" data-image="https://drive.google.com/uc?export=view&amp;id=16QZxIsrE1YY_3AnGzaV9pN9DTUUOko4r" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/social-share.js/dist/css/share.min.css"><script src="https://cdn.jsdelivr.net/npm/social-share.js/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="next-post pull-full"><a href="/blog.github.io/2020/08/21/Deep-Ensembles-A-Loss-Landscape-Perspective/"><img class="next-cover" data-lazy-src="https://drive.google.com/uc?export=view&amp;id=16QZxIsrE1YY_3AnGzaV9pN9DTUUOko4r" onerror="onerror=null;src='/blog.github.io/img/404.jpg'"><div class="pagination-info"><div class="label">Next Post</div><div class="next_info">Deep Ensembles: A Loss Landscape Perspective (2020) (深度集成：损失纵览概述) 论文阅读</div></div></a></div></nav></article></main><footer id="footer" data-type="color"><div id="footer-wrap"><div class="copyright">&copy;2020 By Hualong Deng</div><div class="framework-info"><span>Framework </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>Theme </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div></div></footer></div><section id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="Read Mode"><i class="fas fa-book-open"></i></button><button id="font_plus" type="button" title="Increase Font Size"><i class="fas fa-plus"></i></button><button id="font_minus" type="button" title="Decrease Font Size"><i class="fas fa-minus"></i></button><button id="darkmode" type="button" title="Switch Between Light And Dark Mode"><i class="fas fa-adjust"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="Setting"><i class="fas fa-cog"></i></button><button class="close" id="mobile-toc-button" type="button" title="Table Of Contents"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="Back To Top"><i class="fas fa-arrow-up"></i></button></div></section><div><script src="https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js"></script><script src="/blog.github.io/js/utils.js"></script><script src="/blog.github.io/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js"></script><script src="https://cdn.jsdelivr.net/npm/instant.page/instantpage.min.js" type="module" defer></script><script src="https://cdn.jsdelivr.net/npm/vanilla-lazyload/dist/lazyload.iife.min.js" async></script><div class="js-pjax"><script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></div></body></html>